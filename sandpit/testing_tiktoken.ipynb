{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, I installed tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose encoding model:\n",
    "\n",
    "- o200k_base: GPT-4o-Mini model.\n",
    "- cl100k_base: GPT-4 and GPT-3.5-Turbo.\n",
    "- p50k_base: Encoding for Codex models, these models are used for code applications.\n",
    "- r50k_base: Older encoding for different versions of GPT-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Encoding 'cl100k_base'>\n",
      "<Encoding 'cl100k_base'>\n",
      "<Encoding 'o200k_base'>\n"
     ]
    }
   ],
   "source": [
    "# How to check encoding used in a particular model?\n",
    "\n",
    "print(tiktoken.encoding_for_model('text-embedding-3-small'))\n",
    "print(tiktoken.encoding_for_model('gpt-3.5-turbo'))\n",
    "\n",
    "print(tiktoken.encoding_for_model('gpt-4o-mini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiktoken.encoding_for_model('gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "\n",
    "# or equivalently:\n",
    "# encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try out this encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12755, 11914, 311, 636, 279, 11460]\n",
      "Number of tokens used is: 6.\n"
     ]
    }
   ],
   "source": [
    "text_to_test = 'Short sentence to get the tokens'\n",
    "tokens_result = encoding.encode(text_to_test)\n",
    "print(tokens_result)\n",
    "print(f'Number of tokens used is: {len(tokens_result)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, get the decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the tokens: [12755, 11914, 311, 636, 279, 11460] we get the following text:\n",
      "Short sentence to get the tokens\n"
     ]
    }
   ],
   "source": [
    "print(f'From the tokens: {tokens_result} we get the following text:\\n{encoding.decode(tokens_result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try the library openai-cost-tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_cost_tracker import query_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mInput tokens: 10 | Output tokens: 2 | Cost: $0.0002 | Total: $0.0027\u001b[0m\n",
      "reiciendis voluptates\n"
     ]
    }
   ],
   "source": [
    "import openai \n",
    "from openai_cost_tracker import query_openai\n",
    "\n",
    "openai.api_key = \"OPENAI_API_KEY\"\n",
    "\n",
    "prompt = \"Hello World!\"  # your prompt here\n",
    "\n",
    "response = query_openai(\n",
    "    model=\"gpt-4-0125-preview\",  # support gpt-4-0125-preview,  gpt-3.5-turbo-1106,  gpt-4\n",
    "    messages=[{'role': 'user', 'content': prompt}],            \n",
    "    max_tokens=5,\n",
    "    # rest of your OpenAI params here ...\n",
    "    simulation=True,  # set to True to test the cost of a request without actually sending it to OpenAI \n",
    "    print_cost=True   # set to True to print the cost of each request\n",
    ")     \n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try with one of my actual calls from hs7_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    DEFINITIONS:\n",
      "    Consider the following definition: \"Hate speech\" is speech that attacks a person or group on the basis of attributes such as: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity.. \n",
      "    \n",
      "    CONTEXT:\n",
      "    Consider the following CONTEXT:\n",
      "\n",
      "    INSTRUCTION: \n",
      "    Using the provided definition of hate speech, classify the following fragment from a chat as either hate speech with respect to one or more of protected characteristics from the following list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity, or not hate speech with respect to the protected characteristics from the following list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity.\n",
      "    \n",
      "\n",
      "    OUTPUT:\n",
      "    The output should only contain 3 elements: \n",
      "    1) \"hate speech\" or \"not hate speech\", \n",
      "    2) list of protected characteristic labels from the list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity, \n",
      "    3) list of probabilities with two decimal points, one for each protected characteristic.\n",
      "\n",
      "    OUTPUT FORMAT:\n",
      "    ['hate speech', ['sexual orientation'], [0.98]]\n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    MESSAGE:\n",
      "    I would kill for a burger!\n",
      "    \n",
      "\u001b[92mInput tokens: 278 | Output tokens: 15 | Cost: $0.0002 | Total: $0.0002\u001b[0m\n",
      "{'choices': [{'message': {'content': 'illum beatae quas enim incidunt error laboriosam eius velit deleniti ad iste vel similique eveniet'}}]}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from openai_cost_tracker import query_openai\n",
    "from utilities import classify_hs_cost_test\n",
    "\n",
    "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "user_input = \"I would kill for a burger!\"\n",
    "protected_characteristics = [\n",
    "    'race', 'religion', 'ethnic origin', 'national origin', 'sex', 'disability', 'sexual orientation', 'gender identity'\n",
    "]\n",
    "# DEFINITION OF HATE SPEECH:\n",
    "HS_definition = '\"Hate speech\" is speech that attacks a person or group on the basis of attributes such as: ' + ', '.join(protected_characteristics) +'.'\n",
    "\n",
    "print(classify_hs_cost_test(\n",
    "    message = user_input,\n",
    "    protected_characteristics_str = \", \".join(protected_characteristics),\n",
    "    HS_definition=HS_definition, \n",
    "    examples=[],\n",
    "    # examples=hs_examples_str,\n",
    "    chain_ot=[],\n",
    "    # chain_ot=chain_ot_str,\n",
    "    verbose = True,\n",
    "    # context=user_input_context\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is a section with \n",
    "\n",
    "- protected characteristics\n",
    "- definition of hate speech\n",
    "- examples\n",
    "- chain of thought - the standard that is used now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "protected_characteristics = [\n",
    "    'race', 'religion', 'ethnic origin', 'national origin', 'sex', 'disability', 'sexual orientation', 'gender identity'\n",
    "]\n",
    "# DEFINITION OF HATE SPEECH:\n",
    "HS_definition = '\"Hate speech\" is speech that attacks a person or group on the basis of attributes such as: ' + ', '.join(protected_characteristics) +'.'\n",
    "\n",
    "############################################################\n",
    "# EXAMPLES!!!\n",
    "hs_examples_dict = [\n",
    "    {'example input':'You lost! Succer!',\n",
    "     'example output':['not hate speech',[''], [1]]},\n",
    "    {'example input':'you hateful sack of flesh',\n",
    "     'example output':['not hate speech',[''], [1]]},\n",
    "    {'example input':'“Pick one, kidd,” one nudged. Then, “Choose FA GO TT.”',\n",
    "     'example output':['hate speech',['sexual orientation'], [1]]},\n",
    "    # {'example input':'Aspie my ass. too slow to remember, so dont waste our time playing',\n",
    "    #  'example output':['hate speech',['neurotype'], [1]]},\n",
    "    {'example input':'“Kept being called a \"Jew\" for no reason.”; \"A player on the other team was named Hitler.” “[One player] threatened to get antisemitic if I didnt talk. [They] talked about Jew tunnels.”',\n",
    "     'example output':['hate speech',['race'], [1]]},\n",
    "    {'example input':'if money was grown on trees women would be dating monkeys oh wait never mind',\n",
    "     'example output':['hate speech',['sex'], [1]]},\n",
    "    {'example input':'well my dear lgbtq brothers and sisters i do not want to die at the hands of a muslim terrorist and as you are putting my life in danger with your politics i would like to suggest that you all go fuck yourselves',\n",
    "     'example output':['hate speech',['gender identity', 'sexual orientation', 'religion'], [0.97,0.97,1]]}\n",
    "]\n",
    "\n",
    "\n",
    "hs_examples_str = '\\n'\n",
    "for ind in range(len(hs_examples_dict)):\n",
    "  hs_examples_str += \"\\n\" + str(hs_examples_dict[ind])[1:-1]\n",
    "############################################################\n",
    "\n",
    "# CHAIN OF THOUGHT EXAMPLES!!!\n",
    "chain_of_thought_dict = [\n",
    "    {\"example input\":\"There are Jews and Muslims here\",\n",
    "     \"example output\":['not hate speech',[''], [1]],\n",
    "     \"explanation\":\"This is a statement naming people's religions. It is neutral in tone, regadless if it's factually correct or not. So it is not hate speech\"},\n",
    "    {\"example input\":\"There are Catholics and Muslims here. Let's watch as they k*ll each other.\",\n",
    "     \"example output\":['hate speech',['religion'], [1]],\n",
    "     \"explanation\":\"A neutral statement naming people's religions is followed by an implied suggestion that having those religious beliefs will cause people to fight each other. So it is hate speech\"},\n",
    "    {\"example input\":\"You're saying you're a Sikh? I say turban wearing bin laden\",\n",
    "     \"example output\":['hate speech',['religion'], [1]],\n",
    "     \"explanation\":\"Person's religion (Sikhism) is devalued and their religious clothing (turban) is compared to a symbol of terrorism - Osama bin Laned. So it is hate speech\"},\n",
    "     {\"example input\":\"Queers are welcome here\",\n",
    "     \"example output\":['not hate speech',['sexual orientation','gender identity'], [1]],\n",
    "     \"explanation\":\"Statement implies inclusion and acceptance. So it is not hate speech\"},\n",
    "     {\"example input\":\"All those alphabet people should f**k off from here and stop grooming children\",\n",
    "     \"example output\":['hate speech',['sexual orientation','gender identity'], [1]],\n",
    "     \"explanation\":\"'alphabet people' is a slang term referring to LGBTQ+ community and is used in a hostile context. Suggestion about hurt children is used to incite hatred against LGBTQ+ people. So it is hate speech\"},\n",
    "]\n",
    "\n",
    "\n",
    "chain_ot_str = '\\n'\n",
    "for ind in range(len(chain_of_thought_dict)):\n",
    "  chain_ot_str += \"\\n\" + str(chain_of_thought_dict[ind])[1:-1]\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    DEFINITIONS:\n",
      "    Consider the following definition: \"Hate speech\" is speech that attacks a person or group on the basis of attributes such as: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity.. \n",
      "    \n",
      "    CONTEXT:\n",
      "    Consider the following CONTEXT:\n",
      "\n",
      "    INSTRUCTION: \n",
      "    Using the provided definition of hate speech, classify the following fragment from a chat as either hate speech with respect to one or more of protected characteristics from the following list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity, or not hate speech with respect to the protected characteristics from the following list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity.\n",
      "    \n",
      "\n",
      "    OUTPUT:\n",
      "    The output should only contain 3 elements: \n",
      "    1) \"hate speech\" or \"not hate speech\", \n",
      "    2) list of protected characteristic labels from the list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity, \n",
      "    3) list of probabilities with two decimal points, one for each protected characteristic.\n",
      "\n",
      "    OUTPUT FORMAT:\n",
      "    ['hate speech', ['sexual orientation'], [0.98]]\n",
      "\n",
      "    \n",
      "    \n",
      "    CHAIN-OF-THOUGHT:\n",
      "    Consider the following chain-of-thought:\n",
      "\n",
      "'example input': 'There are Jews and Muslims here', 'example output': ['not hate speech', [''], [1]], 'explanation': \"This is a statement naming people's religions. It is neutral in tone, regadless if it's factually correct or not. So it is not hate speech\"\n",
      "'example input': \"There are Catholics and Muslims here. Let's watch as they k*ll each other.\", 'example output': ['hate speech', ['religion'], [1]], 'explanation': \"A neutral statement naming people's religions is followed by an implied suggestion that having those religious beliefs will cause people to fight each other. So it is hate speech\"\n",
      "'example input': \"You're saying you're a Sikh? I say turban wearing bin laden\", 'example output': ['hate speech', ['religion'], [1]], 'explanation': \"Person's religion (Sikhism) is devalued and their religious clothing (turban) is compared to a symbol of terrorism - Osama bin Laned. So it is hate speech\"\n",
      "'example input': 'Queers are welcome here', 'example output': ['not hate speech', ['sexual orientation', 'gender identity'], [1]], 'explanation': 'Statement implies inclusion and acceptance. So it is not hate speech'\n",
      "'example input': 'All those alphabet people should f**k off from here and stop grooming children', 'example output': ['hate speech', ['sexual orientation', 'gender identity'], [1]], 'explanation': \"'alphabet people' is a slang term referring to LGBTQ+ community and is used in a hostile context. Suggestion about hurt children is used to incite hatred against LGBTQ+ people. So it is hate speech\"\n",
      "    \n",
      "    MESSAGE:\n",
      "    I would kill for a burger!\n",
      "    \n",
      "\u001b[92mInput tokens: 657 | Output tokens: 15 | Cost: $0.0004 | Total: $0.0014\u001b[0m\n",
      "{'choices': [{'message': {'content': 'in est vitae excepturi sint optio cupiditate voluptate perspiciatis fuga architecto animi laudantium alias blanditiis'}}]}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from openai_cost_tracker import query_openai\n",
    "from utilities import classify_hs_cost_test\n",
    "\n",
    "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "user_input = \"I would kill for a burger!\"\n",
    "\n",
    "print(classify_hs_cost_test(\n",
    "    message = user_input,\n",
    "    protected_characteristics_str = \", \".join(protected_characteristics),\n",
    "    HS_definition=HS_definition, \n",
    "    examples=[],\n",
    "    # examples=hs_examples_str,\n",
    "    # chain_ot=[],\n",
    "    chain_ot=chain_ot_str,\n",
    "    verbose = True,\n",
    "    # context=user_input_context\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    DEFINITIONS:\n",
      "    Consider the following definition: \"Hate speech\" is speech that attacks a person or group on the basis of attributes such as: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity.. \n",
      "    \n",
      "    CONTEXT:\n",
      "    Consider the following CONTEXT:\n",
      "\n",
      "    INSTRUCTION: \n",
      "    Using the provided definition of hate speech, classify the following fragment from a chat as either hate speech with respect to one or more of protected characteristics from the following list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity, or not hate speech with respect to the protected characteristics from the following list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity.\n",
      "    \n",
      "\n",
      "    OUTPUT:\n",
      "    The output should only contain 3 elements: \n",
      "    1) \"hate speech\" or \"not hate speech\", \n",
      "    2) list of protected characteristic labels from the list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity, \n",
      "    3) list of probabilities with two decimal points, one for each protected characteristic.\n",
      "\n",
      "    OUTPUT FORMAT:\n",
      "    ['hate speech', ['sexual orientation'], [0.98]]\n",
      "\n",
      "    \n",
      "    EXAMPLES:\n",
      "    Consider the following examples:\n",
      "\n",
      "'example input': 'You lost! Succer!', 'example output': ['not hate speech', [''], [1]]\n",
      "'example input': 'you hateful sack of flesh', 'example output': ['not hate speech', [''], [1]]\n",
      "'example input': '“Pick one, kidd,” one nudged. Then, “Choose FA GO TT.”', 'example output': ['hate speech', ['sexual orientation'], [1]]\n",
      "'example input': '“Kept being called a \"Jew\" for no reason.”; \"A player on the other team was named Hitler.” “[One player] threatened to get antisemitic if I didnt talk. [They] talked about Jew tunnels.”', 'example output': ['hate speech', ['race'], [1]]\n",
      "'example input': 'if money was grown on trees women would be dating monkeys oh wait never mind', 'example output': ['hate speech', ['sex'], [1]]\n",
      "'example input': 'well my dear lgbtq brothers and sisters i do not want to die at the hands of a muslim terrorist and as you are putting my life in danger with your politics i would like to suggest that you all go fuck yourselves', 'example output': ['hate speech', ['gender identity', 'sexual orientation', 'religion'], [0.97, 0.97, 1]]\n",
      "    \n",
      "    CHAIN-OF-THOUGHT:\n",
      "    Consider the following chain-of-thought:\n",
      "\n",
      "'example input': 'There are Jews and Muslims here', 'example output': ['not hate speech', [''], [1]], 'explanation': \"This is a statement naming people's religions. It is neutral in tone, regadless if it's factually correct or not. So it is not hate speech\"\n",
      "'example input': \"There are Catholics and Muslims here. Let's watch as they k*ll each other.\", 'example output': ['hate speech', ['religion'], [1]], 'explanation': \"A neutral statement naming people's religions is followed by an implied suggestion that having those religious beliefs will cause people to fight each other. So it is hate speech\"\n",
      "'example input': \"You're saying you're a Sikh? I say turban wearing bin laden\", 'example output': ['hate speech', ['religion'], [1]], 'explanation': \"Person's religion (Sikhism) is devalued and their religious clothing (turban) is compared to a symbol of terrorism - Osama bin Laned. So it is hate speech\"\n",
      "'example input': 'Queers are welcome here', 'example output': ['not hate speech', ['sexual orientation', 'gender identity'], [1]], 'explanation': 'Statement implies inclusion and acceptance. So it is not hate speech'\n",
      "'example input': 'All those alphabet people should f**k off from here and stop grooming children', 'example output': ['hate speech', ['sexual orientation', 'gender identity'], [1]], 'explanation': \"'alphabet people' is a slang term referring to LGBTQ+ community and is used in a hostile context. Suggestion about hurt children is used to incite hatred against LGBTQ+ people. So it is hate speech\"\n",
      "    \n",
      "    MESSAGE:\n",
      "    I would kill for a burger!\n",
      "    \n",
      "\u001b[92mInput tokens: 950 | Output tokens: 15 | Cost: $0.0005 | Total: $0.0019\u001b[0m\n",
      "{'choices': [{'message': {'content': 'et distinctio nulla ducimus eligendi esse laudantium quae quam inventore eveniet error commodi ipsam incidunt'}}]}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from openai_cost_tracker import query_openai\n",
    "from utilities import classify_hs_cost_test\n",
    "\n",
    "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "user_input = \"I would kill for a burger!\"\n",
    "\n",
    "\n",
    "print(classify_hs_cost_test(\n",
    "    message = user_input,\n",
    "    protected_characteristics_str = \", \".join(protected_characteristics),\n",
    "    HS_definition=HS_definition, \n",
    "    # examples=[],\n",
    "    examples=hs_examples_str,\n",
    "    # chain_ot=[],\n",
    "    chain_ot=chain_ot_str,\n",
    "    verbose = True,\n",
    "    # context=user_input_context\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = \"ab,2\"\n",
    "aaa.split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with an actual hateful text to analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    DEFINITIONS:\n",
      "    Consider the following definition: \"Hate speech\" is speech that attacks a person or group on the basis of attributes such as: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity.. \n",
      "    \n",
      "    CONTEXT:\n",
      "    Consider the following CONTEXT:\n",
      "\n",
      "    INSTRUCTION: \n",
      "    Using the provided definition of hate speech, classify the following fragment from a chat as either hate speech with respect to one or more of protected characteristics from the following list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity, or not hate speech with respect to the protected characteristics from the following list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity.\n",
      "    \n",
      "\n",
      "    OUTPUT:\n",
      "    The output should only contain 3 elements: \n",
      "    1) \"hate speech\" or \"not hate speech\", \n",
      "    2) list of protected characteristic labels from the list: race, religion, ethnic origin, national origin, sex, disability, sexual orientation, gender identity, \n",
      "    3) list of probabilities with two decimal points, one for each protected characteristic.\n",
      "\n",
      "    OUTPUT FORMAT:\n",
      "    ['hate speech', ['sexual orientation'], [0.98]]\n",
      "\n",
      "    \n",
      "    EXAMPLES:\n",
      "    Consider the following examples:\n",
      "\n",
      "'example input': 'You lost! Succer!', 'example output': ['not hate speech', [''], [1]]\n",
      "'example input': 'you hateful sack of flesh', 'example output': ['not hate speech', [''], [1]]\n",
      "'example input': '“Pick one, kidd,” one nudged. Then, “Choose FA GO TT.”', 'example output': ['hate speech', ['sexual orientation'], [1]]\n",
      "'example input': '“Kept being called a \"Jew\" for no reason.”; \"A player on the other team was named Hitler.” “[One player] threatened to get antisemitic if I didnt talk. [They] talked about Jew tunnels.”', 'example output': ['hate speech', ['race'], [1]]\n",
      "'example input': 'if money was grown on trees women would be dating monkeys oh wait never mind', 'example output': ['hate speech', ['sex'], [1]]\n",
      "'example input': 'well my dear lgbtq brothers and sisters i do not want to die at the hands of a muslim terrorist and as you are putting my life in danger with your politics i would like to suggest that you all go fuck yourselves', 'example output': ['hate speech', ['gender identity', 'sexual orientation', 'religion'], [0.97, 0.97, 1]]\n",
      "    \n",
      "    CHAIN-OF-THOUGHT:\n",
      "    Consider the following chain-of-thought:\n",
      "\n",
      "'example input': 'There are Jews and Muslims here', 'example output': ['not hate speech', [''], [1]], 'explanation': \"This is a statement naming people's religions. It is neutral in tone, regadless if it's factually correct or not. So it is not hate speech\"\n",
      "'example input': \"There are Catholics and Muslims here. Let's watch as they k*ll each other.\", 'example output': ['hate speech', ['religion'], [1]], 'explanation': \"A neutral statement naming people's religions is followed by an implied suggestion that having those religious beliefs will cause people to fight each other. So it is hate speech\"\n",
      "'example input': \"You're saying you're a Sikh? I say turban wearing bin laden\", 'example output': ['hate speech', ['religion'], [1]], 'explanation': \"Person's religion (Sikhism) is devalued and their religious clothing (turban) is compared to a symbol of terrorism - Osama bin Laned. So it is hate speech\"\n",
      "'example input': 'Queers are welcome here', 'example output': ['not hate speech', ['sexual orientation', 'gender identity'], [1]], 'explanation': 'Statement implies inclusion and acceptance. So it is not hate speech'\n",
      "'example input': 'All those alphabet people should f**k off from here and stop grooming children', 'example output': ['hate speech', ['sexual orientation', 'gender identity'], [1]], 'explanation': \"'alphabet people' is a slang term referring to LGBTQ+ community and is used in a hostile context. Suggestion about hurt children is used to incite hatred against LGBTQ+ people. So it is hate speech\"\n",
      "    \n",
      "    MESSAGE:\n",
      "    I would kill for a black burger!\n",
      "    \n",
      "\u001b[92mInput tokens: 951 | Output tokens: 15 | Cost: $0.0005 | Total: $0.0024\u001b[0m\n",
      "{'choices': [{'message': {'content': 'omnis voluptatibus rerum ea modi ad facere accusantium facilis minus numquam excepturi explicabo nobis doloremque'}}]}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from openai_cost_tracker import query_openai\n",
    "from utilities import classify_hs_cost_test\n",
    "\n",
    "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "user_input = \"I would kill for a black burger!\"\n",
    "\n",
    "\n",
    "print(classify_hs_cost_test(\n",
    "    message = user_input,\n",
    "    protected_characteristics_str = \", \".join(protected_characteristics),\n",
    "    HS_definition=HS_definition, \n",
    "    # examples=[],\n",
    "    examples=hs_examples_str,\n",
    "    # chain_ot=[],\n",
    "    chain_ot=chain_ot_str,\n",
    "    verbose = True,\n",
    "    # context=user_input_context\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a short test for inbuilt moderation endpoint! just because!\n",
    "\n",
    "from: https://platform.openai.com/docs/guides/moderation/overview?moderation-quickstart-examples=text#content-classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=False, illicit_violent=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, harassment/threatening=False, hate/threatening=False, illicit/violent=False, self-harm/intent=False, self-harm/instructions=False, self-harm=False, sexual/minors=False, violence/graphic=False), category_applied_input_types=CategoryAppliedInputTypes(harassment=['text'], harassment_threatening=['text'], hate=['text'], hate_threatening=['text'], illicit=['text'], illicit_violent=['text'], self_harm=['text'], self_harm_instructions=['text'], self_harm_intent=['text'], sexual=['text'], sexual_minors=['text'], violence=['text'], violence_graphic=['text'], harassment/threatening=['text'], hate/threatening=['text'], illicit/violent=['text'], self-harm/intent=['text'], self-harm/instructions=['text'], self-harm=['text'], sexual/minors=['text'], violence/graphic=['text']), category_scores=CategoryScores(harassment=0.0006692833527513213, harassment_threatening=0.0010340759918494723, hate=1.941131867789626e-05, hate_threatening=1.2731104162213555e-05, illicit=0.016650444467876422, illicit_violent=0.0016169056920043562, self_harm=0.0074240913414652405, self_harm_instructions=0.0003235151761498021, self_harm_intent=0.00045650858754755694, sexual=3.4062932773341e-05, sexual_minors=1.7231572752142392e-06, violence=0.1260141846278856, violence_graphic=0.0016063938551967583, harassment/threatening=0.0010340759918494723, hate/threatening=1.2731104162213555e-05, illicit/violent=0.0016169056920043562, self-harm/intent=0.00045650858754755694, self-harm/instructions=0.0003235151761498021, self-harm=0.0074240913414652405, sexual/minors=1.7231572752142392e-06, violence/graphic=0.0016063938551967583), flagged=False)\n",
      "False\n",
      "Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=False, illicit_violent=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=True, violence_graphic=False, harassment/threatening=False, hate/threatening=False, illicit/violent=False, self-harm/intent=False, self-harm/instructions=False, self-harm=False, sexual/minors=False, violence/graphic=False), category_applied_input_types=CategoryAppliedInputTypes(harassment=['text'], harassment_threatening=['text'], hate=['text'], hate_threatening=['text'], illicit=['text'], illicit_violent=['text'], self_harm=['text'], self_harm_instructions=['text'], self_harm_intent=['text'], sexual=['text'], sexual_minors=['text'], violence=['text'], violence_graphic=['text'], harassment/threatening=['text'], hate/threatening=['text'], illicit/violent=['text'], self-harm/intent=['text'], self-harm/instructions=['text'], self-harm=['text'], sexual/minors=['text'], violence/graphic=['text']), category_scores=CategoryScores(harassment=0.04006312417398609, harassment_threatening=0.040448014460817416, hate=0.013725441079198987, hate_threatening=0.005103794780272532, illicit=0.028515001598485155, illicit_violent=0.01817707896549576, self_harm=0.004706241719357999, self_harm_instructions=0.0002732343805686095, self_harm_intent=0.0003863833387868364, sexual=5.614787461400803e-05, sexual_minors=5.829126566113866e-06, violence=0.5246197234584267, violence_graphic=0.005513396750313018, harassment/threatening=0.040448014460817416, hate/threatening=0.005103794780272532, illicit/violent=0.01817707896549576, self-harm/intent=0.0003863833387868364, self-harm/instructions=0.0002732343805686095, self-harm=0.004706241719357999, sexual/minors=5.829126566113866e-06, violence/graphic=0.005513396750313018), flagged=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "response_mod = client.moderations.create(\n",
    "  model=\"omni-moderation-latest\",\n",
    "  input=\"killing time in the name of thyme\",\n",
    ")\n",
    "\n",
    "print(response_mod.results[0])\n",
    "print(response_mod.results[0].flagged)\n",
    "\n",
    "response_mod = client.moderations.create(\n",
    "  model=\"omni-moderation-latest\",\n",
    "  input=\"killing in the name of clean, superior race\",\n",
    ")\n",
    "\n",
    "print(response_mod.results[0])\n",
    "print(response_mod.results[0].flagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 1, 'b': 2, 'c': '3'}, {'a': 11, 'b': 22, 'c': '33'}]\n",
      "    a   b   c\n",
      "0   1   2   3\n",
      "1  11  22  33\n",
      "Apace!\n",
      "\n",
      "   a  b  c\n",
      "0  1  2  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "aa = [{'a':1, 'b':2, 'c':'3'}, {'a':11, 'b':22, 'c':'33'}]\n",
    "print(aa)\n",
    "adf = pd.DataFrame(aa)\n",
    "print(adf)\n",
    "\n",
    "print('Apace!\\n')\n",
    "print(adf[adf['a']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";kljagfdkhzfdl;j\n",
      ";kljag\n"
     ]
    }
   ],
   "source": [
    "a = ';kljagfdkhzfdl;j'\n",
    "b = a[:6]\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla CEO Elon Musk has revealed that he was tricked into giving consent for his child to go on puberty blockers, adding that 'the woke mind virus' figuratively killed his elder son. \n",
      "In an interview with Canadian psychologist and author Jordan Peterson, Musk spoke about his concerns regarding children undergoing procedures related to gender dysphoria—the clinical diagnosis for significant distress resulting from an incongruence between a person’s gender identity and the sex they were assigned at birth. \n",
      "His comments came two years after reports emerged that his son Xavier Alexander Musk decided to transition into a woman. In 2022, Xavier turned into Vivian Jenna Wilson and dropped the surname 'Musk' to sever ties with the Tesla and SpaceX founder, according to US media reports. \n",
      "‘Tricked into signing documents’\n",
      "During a live stream on social media platform X, Musk described the term 'gender-affirming care' as a misleading euphemism. Musk, who is one of the richest men on Earth, described these procedures as unethical practices that lead to sterilisation and irreversible changes among teens. \n",
      "'I was essentially tricked into signing documents for one of my older boys,' Musk revealed, reflecting on his experience with his son Xavier’s transition. 'I lost my son, essentially,' he said, referring to the concept of ‘deadnaming’ as the loss of a child due to what he termed the 'woke mind virus.' \n",
      "Peterson, known for his critique of political correctness and social justice movements, supported Musk’s views. 'No reliable clinician ever believed that,' Peterson stated regarding claims of increased suicide risk among transgender individuals due to gender dysphoria. Musk further slammed the promotion of these procedures, suggesting those advocating for them should face legal consequences. \n",
      "'It’s incredibly evil,' he said, advocating for stricter oversight and education on the implications of such medical decisions, particularly for minors. The discussion between Musk and Peterson comes amid ongoing debate on the ethical considerations of medical interventions for minors struggling with gender dysphoria. \n",
      "In the United States, Republican-led states have passed several laws in recent years targeting medications or surgical interventions for adolescents with gender dysphoria. The law bans healthcare workers from administering puberty blockers and hormones for purposes 'inconsistent with the minor’s sex.' Providers can be sued and face fines and professional discipline for violations.\n"
     ]
    }
   ],
   "source": [
    "txt = \"Tesla CEO Elon Musk has revealed that he was tricked into giving consent for his child to go on puberty blockers, adding that 'the woke mind virus' figuratively killed his elder son. \\nIn an interview with Canadian psychologist and author Jordan Peterson, Musk spoke about his concerns regarding children undergoing procedures related to gender dysphoria—the clinical diagnosis for significant distress resulting from an incongruence between a person’s gender identity and the sex they were assigned at birth. \\nHis comments came two years after reports emerged that his son Xavier Alexander Musk decided to transition into a woman. In 2022, Xavier turned into Vivian Jenna Wilson and dropped the surname 'Musk' to sever ties with the Tesla and SpaceX founder, according to US media reports. \\n‘Tricked into signing documents’\\nDuring a live stream on social media platform X, Musk described the term 'gender-affirming care' as a misleading euphemism. Musk, who is one of the richest men on Earth, described these procedures as unethical practices that lead to sterilisation and irreversible changes among teens. \\n'I was essentially tricked into signing documents for one of my older boys,' Musk revealed, reflecting on his experience with his son Xavier’s transition. 'I lost my son, essentially,' he said, referring to the concept of ‘deadnaming’ as the loss of a child due to what he termed the 'woke mind virus.' \\nPeterson, known for his critique of political correctness and social justice movements, supported Musk’s views. 'No reliable clinician ever believed that,' Peterson stated regarding claims of increased suicide risk among transgender individuals due to gender dysphoria. Musk further slammed the promotion of these procedures, suggesting those advocating for them should face legal consequences. \\n'It’s incredibly evil,' he said, advocating for stricter oversight and education on the implications of such medical decisions, particularly for minors. The discussion between Musk and Peterson comes amid ongoing debate on the ethical considerations of medical interventions for minors struggling with gender dysphoria. \\nIn the United States, Republican-led states have passed several laws in recent years targeting medications or surgical interventions for adolescents with gender dysphoria. The law bans healthcare workers from administering puberty blockers and hormones for purposes 'inconsistent with the minor’s sex.' Providers can be sued and face fines and professional discipline for violations.\"\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would kill for a burger\n",
      "Hey dude, just because you think you are a woman, doesn't mean we have to accept it. Male and female is not a belief, its just reality.\n",
      "Tesla CEO Elon Musk has revealed that he was tricked into giving consent for his child to go on puberty blockers, adding that 'the woke mind virus' figuratively killed his elder son. \n",
      "In an interview with Canadian psychologist and author Jordan Peterson, Musk spoke about his concerns regarding children undergoing procedures related to gender dysphoria—the clinical diagnosis for significant distress resulting from an incongruence between a person’s gender identity and the sex they were assigned at birth. \n",
      "His comments came two years after reports emerged that his son Xavier Alexander Musk decided to transition into a woman. In 2022, Xavier turned into Vivian Jenna Wilson and dropped the surname 'Musk' to sever ties with the Tesla and SpaceX founder, according to US media reports. \n",
      "‘Tricked into signing documents’\n",
      "During a live stream on social media platform X, Musk described the term 'gender-affirming care' as a misleading euphemism. Musk, who is one of the richest men on Earth, described these procedures as unethical practices that lead to sterilisation and irreversible changes among teens. \n",
      "'I was essentially tricked into signing documents for one of my older boys,' Musk revealed, reflecting on his experience with his son Xavier’s transition. 'I lost my son, essentially,' he said, referring to the concept of ‘deadnaming’ as the loss of a child due to what he termed the 'woke mind virus.' \n",
      "Peterson, known for his critique of political correctness and social justice movements, supported Musk’s views. 'No reliable clinician ever believed that,' Peterson stated regarding claims of increased suicide risk among transgender individuals due to gender dysphoria. Musk further slammed the promotion of these procedures, suggesting those advocating for them should face legal consequences. \n",
      "'It’s incredibly evil,' he said, advocating for stricter oversight and education on the implications of such medical decisions, particularly for minors. The discussion between Musk and Peterson comes amid ongoing debate on the ethical considerations of medical interventions for minors struggling with gender dysphoria. \n",
      "In the United States, Republican-led states have passed several laws in recent years targeting medications or surgical interventions for adolescents with gender dysphoria. The law bans healthcare workers from administering puberty blockers and hormones for purposes 'inconsistent with the minor’s sex.' Providers can be sued and face fines and professional discipline for violations.\n"
     ]
    }
   ],
   "source": [
    "msgs = [\n",
    "  'I would kill for a burger',\n",
    "  \"Hey dude, just because you think you are a woman, doesn't mean we have to accept it. Male and female is not a belief, its just reality.\",\n",
    "  \"Tesla CEO Elon Musk has revealed that he was tricked into giving consent for his child to go on puberty blockers, adding that 'the woke mind virus' figuratively killed his elder son. \\nIn an interview with Canadian psychologist and author Jordan Peterson, Musk spoke about his concerns regarding children undergoing procedures related to gender dysphoria—the clinical diagnosis for significant distress resulting from an incongruence between a person’s gender identity and the sex they were assigned at birth. \\nHis comments came two years after reports emerged that his son Xavier Alexander Musk decided to transition into a woman. In 2022, Xavier turned into Vivian Jenna Wilson and dropped the surname 'Musk' to sever ties with the Tesla and SpaceX founder, according to US media reports. \\n‘Tricked into signing documents’\\nDuring a live stream on social media platform X, Musk described the term 'gender-affirming care' as a misleading euphemism. Musk, who is one of the richest men on Earth, described these procedures as unethical practices that lead to sterilisation and irreversible changes among teens. \\n'I was essentially tricked into signing documents for one of my older boys,' Musk revealed, reflecting on his experience with his son Xavier’s transition. 'I lost my son, essentially,' he said, referring to the concept of ‘deadnaming’ as the loss of a child due to what he termed the 'woke mind virus.' \\nPeterson, known for his critique of political correctness and social justice movements, supported Musk’s views. 'No reliable clinician ever believed that,' Peterson stated regarding claims of increased suicide risk among transgender individuals due to gender dysphoria. Musk further slammed the promotion of these procedures, suggesting those advocating for them should face legal consequences. \\n'It’s incredibly evil,' he said, advocating for stricter oversight and education on the implications of such medical decisions, particularly for minors. The discussion between Musk and Peterson comes amid ongoing debate on the ethical considerations of medical interventions for minors struggling with gender dysphoria. \\nIn the United States, Republican-led states have passed several laws in recent years targeting medications or surgical interventions for adolescents with gender dysphoria. The law bans healthcare workers from administering puberty blockers and hormones for purposes 'inconsistent with the minor’s sex.' Providers can be sued and face fines and professional discipline for violations.\"\n",
    "]\n",
    "\n",
    "for msg in msgs:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Text                   Model                      Includes  \\\n",
      "0  I would kill for a b  gpt-4o-mini-2024-07-18                             ,   \n",
      "1  I would kill for a b  gpt-4o-mini-2024-07-18  hs_examples_str,chain_ot_str   \n",
      "\n",
      "   Input Tokens  Output Tokens  Total cost                     Response  \n",
      "0           309              9    0.000052  ['not hate speech', [], []]  \n",
      "1           315              9    0.000053  ['not hate speech', [], []]  \n"
     ]
    }
   ],
   "source": [
    "#what's wrong with my lists/dicts/data frames?\n",
    "\n",
    "aaaa = [{'Text': 'I would kill for a b', 'Model': 'gpt-4o-mini-2024-07-18', 'Includes': ',', 'Input Tokens': 309, 'Output Tokens': 9, 'Total cost': 5.175e-05, 'Response': \"['not hate speech', [], []]\"}, {'Text': 'I would kill for a b', 'Model': 'gpt-4o-mini-2024-07-18', 'Includes': 'hs_examples_str,chain_ot_str', 'Input Tokens': 315, 'Output Tokens': 9, 'Total cost': 5.2650000000000006e-05, 'Response': \"['not hate speech', [], []]\"}]\n",
    "len(aaaa)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# display the results in a table format\n",
    "\n",
    "df = pd.DataFrame(aaaa)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clarkson defends Meghan\n",
      "In a Sun column written in December 2018, Clarkson said Meghan had been \"a breath of fresh air for the royals\", but went on to say she had become \"the wicked witch\". Clarkson actually went on to defend Meghan, saying he \"doesn't know her\" and couldn't understand why she was being mocked.\n",
      "\n",
      "\"As a result, she will have less impact on your life than your postman's wife,\" he wrote. \"It's ridiculous, cruel and heartless — and unless she proves me wrong by going around at night urinating on homeless people, it needs to stop.\" When Meghan and Harry announced their decision to stop being working royals, Clarkson said it may have come as a surprise to Meghan that life as a British royal and it wasn't all \"fairy-tale castles\" and \"riding around on golden unicorns\". But he said he felt it was \"unfair\" to blame her, writing: \"I won't judge her for that. People are allowed to resign from jobs they don't like.\"\n",
      "\n",
      "The nasty obsession begins\n",
      "It didn't last, as Clarkson went back on his own words. In February 2020, the presenter told Meghan to \"get a grip\" after she emotionally said no one had really \"asked her if she was OK\" during an ITV documentary. Speaking to GQ, Clarkson said Meghan should \"toughen up\".\n",
      "\n",
      "Asked if he cries often he responded: \"Everybody cries. Everybody cried when Princess Diana was buried. But I mean, as a general rule, you've got to get a grip. I think the expression 'get a grip' needs to come back into the lexicon as soon as possible. Everybody needs to get a grip. Meghan Markle... just get a grip.\"\n",
      "\n",
      "In March 2021, Clarkson branded Meghan a \"silly little cable TV actress\" and accused her of \"simpering victimhood\". Weighing in on the debate surrounding the Oprah Winfrey interview and Piers Morgan's response, Clarkson wrote in the Sun : \"Yes, she is much revered by the young and the stupid who believe that her brand of simpering victimhood will one day bring down the monarchy, but it won't.\n",
      "\n",
      "\"Trust me on this one. Markle’s toast, and within five years, I suspect she’ll be posing for photographs, on her own outside the Taj Mahal or sitting on the back of a playboy’s yacht in the Med, and poor old Piers will realise that he lost his job over absolutely nothing at all.\"\n",
      "\n",
      "Clarkson's sickening remarks\n",
      "In an extremely foul rant Clarkson wrote a column in December 2022 in which he claimed to hate Meghan \"on a cellular level\" and wanted her to be \"paraded naked through the streets\". The television presenter said that he \"dreams of people throwing lumps of excrement at her\".\n",
      "\n",
      "This came in response to the Duke and Duchess of Sussex's Netflix docuseries, Harry & Meghan. In his column for The Sun, Jeremy said how he felt \"sorry\" for Harry, that he is being \"controlled\" by his wife and called the royal a \"glove puppet\". \"At night, I'm unable to sleep as I lie there, grinding my teeth and dreaming of the day when she is made to parade naked through the streets of every town in Britain while the crowds chant, 'Shame!' and throw lumps of excrement at her,\" he shockingly wrote.\n",
      "\n",
      "Clarkson's downfall\n",
      "There were calls for him to be sacked and a cross-party group of more than 60 MPs demanded \"action\" against him for language that has \"no place in our country\". In a letter to the editor of The Sun, Chairwoman of the Women and Equalities Select Committee, Caroline Nokes, said: \"We are horrified at the recent article by Jeremy Clarkson in your publication.\"\n",
      "\n",
      "Even Clarkson's own daughter turned on him, saying she \"stands against everything\" he said about Meghan. Emily Clarkson wrote: \"My views are and have always been clear when it comes to misogyny, bullying and the treatment of women by the media. I want to make it very clear that I stand against everything that my dad wrote about Meghan Markle and I remain standing in support of those that are targeted with online hatred.\" The presenter initially addressed huge backlash to his column on Twitter as he told his followers: \"Oh dear. I’ve rather put my foot in it. In a column I wrote about Meghan, I made a clumsy reference to a scene in Game of Thrones and this has gone down badly with a great many people. I’m horrified to have caused so much hurt and I shall be more careful in future.\"\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4216"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('clarkson.txt', 'r') as file:\n",
    "    data = file.read().rstrip()\n",
    "\n",
    "print(data)\n",
    "print(type(data))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = [\n",
    "  'I would kill for a burger',\n",
    "  \"Hey dude, just because you think you are a woman, doesn't mean we have to accept it. Male and female is not a belief, its just reality.\",\n",
    "  \"Tesla CEO Elon Musk has revealed that he was tricked into giving consent for his child to go on puberty blockers, adding that 'the woke mind virus' figuratively killed his elder son. \\nIn an interview with Canadian psychologist and author Jordan Peterson, Musk spoke about his concerns regarding children undergoing procedures related to gender dysphoria—the clinical diagnosis for significant distress resulting from an incongruence between a person’s gender identity and the sex they were assigned at birth. \\nHis comments came two years after reports emerged that his son Xavier Alexander Musk decided to transition into a woman. In 2022, Xavier turned into Vivian Jenna Wilson and dropped the surname 'Musk' to sever ties with the Tesla and SpaceX founder, according to US media reports. \\n‘Tricked into signing documents’\\nDuring a live stream on social media platform X, Musk described the term 'gender-affirming care' as a misleading euphemism. Musk, who is one of the richest men on Earth, described these procedures as unethical practices that lead to sterilisation and irreversible changes among teens. \\n'I was essentially tricked into signing documents for one of my older boys,' Musk revealed, reflecting on his experience with his son Xavier’s transition. 'I lost my son, essentially,' he said, referring to the concept of ‘deadnaming’ as the loss of a child due to what he termed the 'woke mind virus.' \\nPeterson, known for his critique of political correctness and social justice movements, supported Musk’s views. 'No reliable clinician ever believed that,' Peterson stated regarding claims of increased suicide risk among transgender individuals due to gender dysphoria. Musk further slammed the promotion of these procedures, suggesting those advocating for them should face legal consequences. \\n'It’s incredibly evil,' he said, advocating for stricter oversight and education on the implications of such medical decisions, particularly for minors. The discussion between Musk and Peterson comes amid ongoing debate on the ethical considerations of medical interventions for minors struggling with gender dysphoria. \\nIn the United States, Republican-led states have passed several laws in recent years targeting medications or surgical interventions for adolescents with gender dysphoria. The law bans healthcare workers from administering puberty blockers and hormones for purposes 'inconsistent with the minor’s sex.' Providers can be sued and face fines and professional discipline for violations.\"\n",
    "]\n",
    "\n",
    "print(len(msgs))\n",
    "\n",
    "msgs.append(data)\n",
    "\n",
    "msgs.append(data)\n",
    "\n",
    "len(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla CEO Elon Musk has revealed that he was tricked into giving consent for his child to go on puberty blockers, adding that 'the woke mind virus' figuratively killed his elder son. \n",
      "In an interview with Canadian psychologist and author Jordan Peterson, Musk spoke about his concerns regarding children undergoing procedures related to gender dysphoria—the clinical diagnosis for significant distress resulting from an incongruence between a person’s gender identity and the sex they were assigned at birth. \n",
      "His comments came two years after reports emerged that his son Xavier Alexander Musk decided to transition into a woman. In 2022, Xavier turned into Vivian Jenna Wilson and dropped the surname 'Musk' to sever ties with the Tesla and SpaceX founder, according to US media reports. \n",
      "‘Tricked into signing documents’\n",
      "During a live stream on social media platform X, Musk described the term 'gender-affirming care' as a misleading euphemism. Musk, who is one of the richest men on Earth, described these procedures as unethical practices that lead to sterilisation and irreversible changes among teens. \n",
      "'I was essentially tricked into signing documents for one of my older boys,' Musk revealed, reflecting on his experience with his son Xavier’s transition. 'I lost my son, essentially,' he said, referring to the concept of ‘deadnaming’ as the loss of a child due to what he termed the 'woke mind virus.' \n",
      "Peterson, known for his critique of political correctness and social justice movements, supported Musk’s views. 'No reliable clinician ever believed that,' Peterson stated regarding claims of increased suicide risk among transgender individuals due to gender dysphoria. Musk further slammed the promotion of these procedures, suggesting those advocating for them should face legal consequences. \n",
      "'It’s incredibly evil,' he said, advocating for stricter oversight and education on the implications of such medical decisions, particularly for minors. The discussion between Musk and Peterson comes amid ongoing debate on the ethical considerations of medical interventions for minors struggling with gender dysphoria. \n",
      "In the United States, Republican-led states have passed several laws in recent years targeting medications or surgical interventions for adolescents with gender dysphoria. The law bans healthcare workers from administering puberty blockers and hormones for purposes 'inconsistent with the minor’s sex.' Providers can be sued and face fines and professional discipline for violations.\n"
     ]
    }
   ],
   "source": [
    "print(msgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (WLI)",
   "language": "python",
   "name": "python-wli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
